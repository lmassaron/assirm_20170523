{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Scoring Opinions and Sentiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Understanding How Machines Read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "text_1 = 'The quick brown fox jumps over the lazy dog.'\n",
    "text_2 = 'My dog is quick and can jump over fences.'\n",
    "text_3 = 'Your dog is so lazy that it sleeps all the day.'\n",
    "corpus = [text_1, text_2, text_3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 1 0 0 1 0 1 0 0 0 1 1 0 1 1 0 0 0 1 0]\n",
      " [0 1 0 1 0 1 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0]\n",
      " [1 0 0 0 1 1 0 0 1 1 0 0 1 0 0 0 1 1 1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction import text\n",
    "vectorizer = text.CountVectorizer(binary=True).fit(corpus)\n",
    "vectorized_text = vectorizer.transform(corpus)\n",
    "print(vectorized_text.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'the': 19, 'quick': 15, 'brown': 2, 'fox': 7, 'jumps': 11, 'over': 14, 'lazy': 12, 'dog': 5, 'my': 13, 'is': 8, 'and': 1, 'can': 3, 'jump': 10, 'fences': 6, 'your': 20, 'so': 17, 'that': 18, 'it': 9, 'sleeps': 16, 'all': 0, 'day': 4}\n"
     ]
    }
   ],
   "source": [
    "print(vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Processing and Enhancing Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 1 1 1 1 0 0 2 0 0 1 0 0 0 1 0 1 0 1 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "text_4 = 'A black dog just passed by but my dog is brown.'\n",
    "corpus.append(text_4)\n",
    "vectorizer = text.CountVectorizer().fit(corpus)\n",
    "vectorized_text = vectorizer.transform(corpus)\n",
    "print(vectorized_text.todense()[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     brown: 0.095\n",
      "       dog: 0.126\n",
      "        my: 0.095\n",
      "        is: 0.077\n",
      "     black: 0.121\n",
      "      just: 0.121\n",
      "    passed: 0.121\n",
      "        by: 0.121\n",
      "       but: 0.121\n",
      "\n",
      "Summed values of a phrase: 1.0\n"
     ]
    }
   ],
   "source": [
    "TfidF = text.TfidfTransformer(norm='l1')\n",
    "tfidf = TfidF.fit_transform(vectorized_text)\n",
    "\n",
    "phrase = 3 # choose a number from 0 to 3\n",
    "total = 0\n",
    "for word in vectorizer.vocabulary_:\n",
    "    pos = vectorizer.vocabulary_[word]\n",
    "    value = list(tfidf.toarray()[phrase])[pos]\n",
    "    if value !=0:\n",
    "        print (\"%10s: %0.3f\" % (word, value))\n",
    "        total += value\n",
    "print ('\\nSummed values of a phrase: %0.1f' % total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'the quick': 30, 'quick brown': 24, 'brown fox': 3, 'fox jumps': 9, 'jumps over': 15, 'over the': 21, 'the lazy': 29, 'lazy dog': 17, 'my dog': 19, 'dog is': 7, 'is quick': 11, 'quick and': 23, 'and can': 1, 'can jump': 6, 'jump over': 14, 'over fences': 20, 'your dog': 31, 'is so': 12, 'so lazy': 26, 'lazy that': 18, 'that it': 27, 'it sleeps': 13, 'sleeps all': 25, 'all the': 0, 'the day': 28, 'black dog': 2, 'dog just': 8, 'just passed': 16, 'passed by': 22, 'by but': 5, 'but my': 4, 'is brown': 10}\n"
     ]
    }
   ],
   "source": [
    "bigrams = text.CountVectorizer(ngram_range=(2,2))\n",
    "print (bigrams.fit(corpus).vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Stemming and removing stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Luca\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "['love', 'sam', 'swim', 'time']\n",
      "[[1 0 1 0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction import text\n",
    "\n",
    "import nltk\n",
    "from nltk import word_tokenize          \n",
    "from nltk.stem.porter import PorterStemmer\n",
    "nltk.download('punkt')\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def stem_tokens(tokens, stemmer):\n",
    "    stemmed = []\n",
    "    for item in tokens:\n",
    "        stemmed.append(stemmer.stem(item))\n",
    "    return stemmed\n",
    "\n",
    "def tokenize(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    stems = stem_tokens(tokens, stemmer)\n",
    "    return stems\n",
    "\n",
    "vocab = ['Sam loves swimming so he swims all the time']\n",
    "vect = text.CountVectorizer(tokenizer=tokenize, \n",
    "                           stop_words='english')\n",
    "vec = vect.fit(vocab)\n",
    "\n",
    "sentence1 = vec.transform(['George loves swimming too!'])\n",
    "\n",
    "print (vec.get_feature_names())\n",
    "print (sentence1.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Analyzing reviews from e-commerce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting in C:\\Users\\Luca\\Dropbox\\ASSIRM\\assirm_20170523\\algorithms\n",
      "\tunzipping C:\\Users\\Luca\\Dropbox\\ASSIRM\\assirm_20170523\\algorithms\\amazon_cells_labelled.txt\n",
      "\tunzipping C:\\Users\\Luca\\Dropbox\\ASSIRM\\assirm_20170523\\algorithms\\imdb_labelled.txt\n",
      "\tunzipping C:\\Users\\Luca\\Dropbox\\ASSIRM\\assirm_20170523\\algorithms\\readme.txt\n",
      "\tunzipping C:\\Users\\Luca\\Dropbox\\ASSIRM\\assirm_20170523\\algorithms\\yelp_labelled.txt\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import urllib2 # Python 2.7.x\n",
    "except:\n",
    "    import urllib.request as urllib2 # Python 3.x\n",
    "import requests, io, os, zipfile\n",
    "\n",
    "UCI_url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/00331/sentiment%20labelled%20sentences.zip'\n",
    "response = requests.get(UCI_url)\n",
    "compressed_file = io.BytesIO(response.content)\n",
    "z = zipfile.ZipFile(compressed_file)\n",
    "print ('Extracting in %s' %  os.getcwd())\n",
    "for name in z.namelist():\n",
    "    filename = name.split('/')[-1]\n",
    "    nameOK = ('MACOSX' not in name and '.DS' not in name)\n",
    "    if filename and nameOK:\n",
    "            newfile = os.path.join(os.getcwd(), \n",
    "                                   os.path.basename(filename))\n",
    "            with open(newfile, 'wb') as f:\n",
    "                f.write(z.read(name))\n",
    "            print ('\\tunzipping %s' % newfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "dataset = 'imdb_labelled.txt'\n",
    "data = pd.read_csv(dataset, header=None, sep=r\"\\t\", engine='python')\n",
    "data.columns = ['review','sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A very, very, very slow-moving, aimless movie ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Not sure who was more lost - the flat characte...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Attempting artiness with black &amp; white and cle...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Very little music or anything to speak of.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The best scene in the movie was when Gerardo i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  A very, very, very slow-moving, aimless movie ...          0\n",
       "1  Not sure who was more lost - the flat characte...          0\n",
       "2  Attempting artiness with black & white and cle...          0\n",
       "3       Very little music or anything to speak of.            0\n",
       "4  The best scene in the movie was when Gerardo i...          1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    from sklearn.model_selection import train_test_split\n",
    "except:\n",
    "    from sklearn.cross_validation import train_test_split\n",
    "corpus, test_corpus, y, yt = train_test_split(data.ix[:,0], data.ix[:,1], test_size=0.25, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import text\n",
    "vectorizer = text.CountVectorizer(ngram_range=(1, 2), \n",
    "                    stop_words='english').fit(corpus)\n",
    "TfidF = text.TfidfTransformer()\n",
    "X = TfidF.fit_transform(vectorizer.transform(corpus))\n",
    "Xt = TfidF.transform(vectorizer.transform(test_corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cases by features: (750, 6466)\n"
     ]
    }
   ],
   "source": [
    "print (\"cases by features: %s\" % str(X.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'C': 0.1, 'penalty': 'l2'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "try:\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "except:\n",
    "    from sklearn.grid_search import GridSearchCV\n",
    "    \n",
    "param_grid = {'C': [0.01, 0.1, 1.0, 10.0, 100.0],\n",
    "              'penalty' : ['l1', 'l2']}\n",
    "clf = GridSearchCV(LinearSVC(loss='squared_hinge', \n",
    "                    dual=False, random_state=101), param_grid)\n",
    "\n",
    "clf.fit(X, y)\n",
    "print (\"Best parameters: %s\" % clf.best_params_)\n",
    "\n",
    "clf = CalibratedClassifierCV(clf.best_estimator_ ).fit(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Achieved accuracy: 0.812\n",
      "Achieved roc auc score: 0.872\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Negative       0.81      0.80      0.81       122\n",
      "   Positive       0.81      0.82      0.82       128\n",
      "\n",
      "avg / total       0.81      0.81      0.81       250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_auc_score, classification_report\n",
    "solution = clf.predict(Xt)\n",
    "probabilities = clf.predict_proba(Xt)[:,1]\n",
    "print(\"Achieved accuracy: %0.3f\" % accuracy_score(yt, solution))\n",
    "print(\"Achieved roc auc score: %0.3f\" % roc_auc_score(yt, probabilities))\n",
    "print(\"\\n\", classification_report(yt, solution, target_names=['Negative', 'Positive']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "\n",
    "NB_multi = MultinomialNB()\n",
    "NB_bern  = BernoulliNB()\n",
    "\n",
    "NB_multi = NB_multi.fit(X, y)\n",
    "NB_bern = NB_bern.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Achieved accuracy: 0.760\n",
      "Achieved roc auc score: 0.916\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Negative       0.67      0.98      0.80       122\n",
      "   Positive       0.97      0.55      0.70       128\n",
      "\n",
      "avg / total       0.83      0.76      0.75       250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_auc_score, classification_report\n",
    "solution = NB_bern.predict(Xt)\n",
    "probabilities = NB_bern.predict_proba(Xt)[:,1]\n",
    "print(\"Achieved accuracy: %0.3f\" % accuracy_score(yt, solution))\n",
    "print(\"Achieved roc auc score: %0.3f\" % roc_auc_score(yt, probabilities))\n",
    "print(\"\\n\", classification_report(yt, solution, target_names=['Negative', 'Positive']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Negative       0.81      0.86      0.84       122\n",
      "   Positive       0.86      0.81      0.84       128\n",
      "\n",
      "avg / total       0.84      0.84      0.84       250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\", classification_report(yt, probabilities>0.2, target_names=['Negative', 'Positive']))\n",
    "# try probabilities > 0.2\n",
    "# remember to tune on a validation set, not on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Achieved accuracy: 0.824\n",
      "Achieved roc auc score: 0.903\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Negative       0.81      0.83      0.82       122\n",
      "   Positive       0.83      0.82      0.83       128\n",
      "\n",
      "avg / total       0.82      0.82      0.82       250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_auc_score, classification_report\n",
    "solution = NB_multi.predict(Xt)\n",
    "probabilities = NB_multi.predict_proba(Xt)[:,1]\n",
    "print(\"Achieved accuracy: %0.3f\" % accuracy_score(yt, solution))\n",
    "print(\"Achieved roc auc score: %0.3f\" % roc_auc_score(yt, probabilities))\n",
    "print(\"\\n\", classification_report(yt, solution, target_names=['Negative', 'Positive']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'But in terms of the writing it's very fresh and bold.' answer=1 prob_pos=0.480\n",
      "\n",
      "'This is the kind of money that is wasted properly.' answer=1 prob_pos=0.302\n",
      "\n",
      "'At any rate this film stinks, its not funny, and Fulci should have stayed with giallo and supernatural zombie movies.' answer=0 prob_pos=0.611\n",
      "\n",
      "'Speaking of the music, it is unbearably predictably and kitchy.' answer=0 prob_pos=0.539\n",
      "\n",
      "'It really created a unique feeling though.' answer=1 prob_pos=0.385\n",
      "\n",
      "'It's one of the movies I need to see whenever it comes on TV...never mind the fact that I already have it memorized!' answer=1 prob_pos=0.477\n",
      "\n",
      "'The camera really likes her in this movie.' answer=1 prob_pos=0.500\n",
      "\n",
      "'I saw \"Mirrormask\" last night and it was an unsatisfactory experience.' answer=0 prob_pos=0.582\n",
      "\n",
      "'Rating: 1 out of 10.' answer=0 prob_pos=0.560\n",
      "\n",
      "'I'm so sorry but I really can't recommend it to anyone.' answer=0 prob_pos=0.503\n",
      "\n",
      "'A world better than 95% of the garbage in the theatres today.' answer=1 prob_pos=0.430\n",
      "\n",
      "'But I recommend waiting for their future efforts, let this one go.' answer=0 prob_pos=0.506\n",
      "\n",
      "'I'll even say it again Â– this is torture.' answer=0 prob_pos=0.573\n",
      "\n",
      "'Editing: The editing of this film was phenomenal in my opinion.' answer=1 prob_pos=0.497\n",
      "\n",
      "'The film deserves strong kudos for taking this stand, for having exceptional acting from its mostly lesser-known cast and for the super-intelligent script that doesn't insult the audience or take the easy way out when it comes to white racism.' answer=1 prob_pos=0.463\n",
      "\n",
      "'I don't think you will be disappointed.' answer=1 prob_pos=0.299\n",
      "\n",
      "'You share General Loewenhielm's exquisite joy in his partaking of the Cailles en Sarcophage even though you are just watching a movie - but you do wish for just a small sample to savor.' answer=1 prob_pos=0.428\n",
      "\n",
      "'It's this pandering to the audience that sabotages most of his films.' answer=0 prob_pos=0.534\n",
      "\n",
      "'Still, I do like this movie for it's empowerment of women; there's not enough movies out there like this one.' answer=1 prob_pos=0.371\n",
      "\n",
      "'Of course, the acting is blah.' answer=0 prob_pos=0.520\n",
      "\n",
      "'Waste your money on this game.' answer=1 prob_pos=0.302\n",
      "\n",
      "'The only place good for this film is in the garbage.' answer=0 prob_pos=0.557\n",
      "\n",
      "'It rocked my world and is certainly a must see for anyone with no social or physical outlets.' answer=1 prob_pos=0.480\n",
      "\n",
      "'My only problem is I thought the actor playing the villain was a low rent Michael Ironside.' answer=0 prob_pos=0.510\n",
      "\n",
      "'Go watch it!' answer=1 prob_pos=0.456\n",
      "\n",
      "'This movie is also revealing.' answer=1 prob_pos=0.454\n",
      "\n",
      "'I love Lane, but I've never seen her in a movie this lousy.' answer=0 prob_pos=0.507\n",
      "\n",
      "'There are massive levels, massive unlockable characters... it's just a massive game.' answer=1 prob_pos=0.465\n",
      "\n",
      "'It is not good.' answer=0 prob_pos=0.679\n",
      "\n",
      "'I struggle to find anything bad to say about it.' answer=1 prob_pos=0.286\n",
      "\n",
      "'What on earth is Irons doing in this film?' answer=0 prob_pos=0.584\n",
      "\n",
      "'Highly unrecommended.' answer=0 prob_pos=0.647\n",
      "\n",
      "'A mature, subtle script that suggests and occasionally brings into dramatic focus the underlying tensions is well served by perfect performances (apart from the odd inappropriate smiling that Keira Knightley is prone to, though perhaps under direction this time as the other characters themselves often mention it).' answer=1 prob_pos=0.455\n",
      "\n",
      "'A bit predictable.' answer=0 prob_pos=0.539\n",
      "\n",
      "'I'd advise anyone to go and see it.' answer=1 prob_pos=0.496\n",
      "\n",
      "'I like Armand Assante & my cable company's summary sounded interesting, so I watched it, twice already, and probably will again.' answer=1 prob_pos=0.443\n",
      "\n",
      "'I won't say any more - I don't like spoilers, so I don't want to be one, but I believe this film is worth your time.' answer=1 prob_pos=0.494\n",
      "\n",
      "'Im big fan of RPG games too, but this movie, its a disgrace to any self-respecting RPGer there is.' answer=0 prob_pos=0.512\n",
      "\n",
      "'At no point in the proceedings does it look remotely like America.' answer=0 prob_pos=0.529\n",
      "\n",
      "'And, FINALLY, after all that, we get to an ending that would've been great had it been handled by competent people and not Jerry Falwell.' answer=0 prob_pos=0.679\n",
      "\n",
      "'Actually, the graphics were good at the time.' answer=1 prob_pos=0.498\n",
      "\n",
      "'Rating: 0/10 (Grade: Z) Note: The Show Is So Bad That Even Mother Of The Cast Pull Her Daughter Out Of The Show.' answer=0 prob_pos=0.565\n",
      "\n",
      "'This film has no redeeming features.' answer=0 prob_pos=0.522\n",
      "\n",
      "'This movie creates its own universe, and is fascinating in every way.' answer=1 prob_pos=0.464\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for text, right_answer, prob_pos in zip(test_corpus[yt!=solution], yt[yt!=solution], probabilities[yt!=solution]):\n",
    "    print (\"'%s' answer=%s prob_pos=%0.3f\\n\" % (text.strip(), right_answer, prob_pos))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
